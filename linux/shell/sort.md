# sort and uniq

keyword: 排序 去重 

-n 按数值大小进行排序
-r 逆序
-k 指定排序的字段
-t 指定分隔符

sort命令对于字母表排序和数字排序有不同的处理方式

```shell
cat > test.txt << EOF
192.168.3.1 00:0F:AF:81:19:1F
192.168.3.2 00:0F:AF:85:6C:25
192.168.3.3 00:0F:AF:85:70:42
192.168.2.20 00:0F:AF:85:55:DE
192.168.2.21 00:0F:AF:85:6C:09
192.168.2.22 00:0F:AF:85:5C:41
192.168.0.151 00:0F:AF:85:6C:F6
192.168.0.152 00:0F:AF:83:1F:65
192.168.1.10 00:30:15:A2:3B:B6
192.168.1.11 00:30:15:A3:23:B7
192.168.1.12 00:30:15:A2:3A:A1
192.168.1.1 00:0F:AF:81:19:1F
192.168.2.2 00:0F:AF:85:6C:25
192.168.3.3 00:0F:AF:85:70:42
192.168.2.20 00:0F:AF:85:55:DE
192.168.1.21 00:0F:AF:85:6C:09
192.168.2.22 00:0F:AF:85:5C:41
192.168.0.151 00:0F:AF:85:6C:F6
192.168.1.152 00:0F:AF:83:1F:65
192.168.3.10 00:30:15:A2:3B:B6
192.168.1.11 00:30:15:A3:23:B7
192.168.3.12 00:30:15:A2:3A:A1
EOF

sort -t. -k3 test.txt 
192.168.0.151 00:0F:AF:85:6C:F6
192.168.0.151 00:0F:AF:85:6C:F6
192.168.0.152 00:0F:AF:83:1F:65
192.168.1.1 00:0F:AF:81:19:1F
192.168.1.10 00:30:15:A2:3B:B6
192.168.1.11 00:30:15:A3:23:B7
192.168.1.11 00:30:15:A3:23:B7
192.168.1.12 00:30:15:A2:3A:A1
192.168.1.152 00:0F:AF:83:1F:65
192.168.1.21 00:0F:AF:85:6C:09  # 可以看到这里排序不太正常
192.168.2.2 00:0F:AF:85:6C:25
192.168.2.20 00:0F:AF:85:55:DE
192.168.2.20 00:0F:AF:85:55:DE
192.168.2.21 00:0F:AF:85:6C:09
192.168.2.22 00:0F:AF:85:5C:41
192.168.2.22 00:0F:AF:85:5C:41
192.168.3.1 00:0F:AF:81:19:1F
192.168.3.10 00:30:15:A2:3B:B6
192.168.3.12 00:30:15:A2:3A:A1
192.168.3.2 00:0F:AF:85:6C:25
192.168.3.3 00:0F:AF:85:70:42
192.168.3.3 00:0F:AF:85:70:42

# -u 去重
# -n 按数值排序
# -k3,3 按第3个字段开始到第3个字段结束排序
# -k4.1,4.3 按第4个字段第1个字符开始到第4个字段第3个字符结束排序
# 以上缺一不可
sort -n -u -t. -k3,3 -k4.1,4.3 test.txt 
192.168.0.151 00:0F:AF:85:6C:F6
192.168.0.152 00:0F:AF:83:1F:65
192.168.1.1 00:0F:AF:81:19:1F
192.168.1.10 00:30:15:A2:3B:B6
192.168.1.11 00:30:15:A3:23:B7
192.168.1.12 00:30:15:A2:3A:A1
192.168.1.21 00:0F:AF:85:6C:09
192.168.1.152 00:0F:AF:83:1F:65
192.168.2.2 00:0F:AF:85:6C:25
192.168.2.20 00:0F:AF:85:55:DE
192.168.2.21 00:0F:AF:85:6C:09
192.168.2.22 00:0F:AF:85:5C:41
192.168.3.1 00:0F:AF:81:19:1F
192.168.3.2 00:0F:AF:85:6C:25
192.168.3.3 00:0F:AF:85:70:42
192.168.3.10 00:30:15:A2:3B:B6
192.168.3.12 00:30:15:A2:3A:A1
```

```shell
cat > data.txt <<EOF
1,mac,2000
2,winxp,4000
3,bsd,1000
4,linux,1000
EOF

sort -t ',' -k 3 -n data.txt
sort -t ',' -k 2 data.txt
sort -t ',' -k 3 -r data.txt 
sort -t ',' -k 2.2 data.txt # 依据第2列第二个字符进行排序
```


## uniq

-c 统计重复次数
-d 只显示重复的行
-u 只显示不重复的行

**uniq只能作用于排过序的数据**，因此，uniq通常都与sort命令结合使用

```shell
cat > unsorted.txt <<EOF
bash
hack
foss
hack
EOF

# 统计各行在文件中出现的次数,明显错误,所以需要先排序
uniq -c unsorted.txt 
      1 bash
      1 hack #<-- 没有识别
      1 foss
      1 hack #<--

# 排序后成功识别
sort unsorted.txt | uniq -c
      1 bash
      1 foss
      2 hack

# 只显示重复的行
sort unsorted.txt | uniq -d 
hack

# 只显示不重复的行
sort unsorted.txt | uniq -u
bash
foss
```